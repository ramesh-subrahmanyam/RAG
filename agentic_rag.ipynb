{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv, os, shutil\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from utils import print_sample_node, setup_indexes, read_indexes, save_indexes\n",
    "from utils import add_to_indexes, VECTOR_INDEX_PATH, SUMMARY_INDEX_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VERBOSE=True\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embedding = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install newspaper3k\n",
    "#pip install lxml[html_clean]\n",
    "#pip install llama-index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Llamaindex documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up indexes for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [VECTOR_INDEX_PATH, SUMMARY_INDEX_PATH]:\n",
    "    if os.path.exists(d):\n",
    "        shutil.rmtree(d)\n",
    "indexes=vector_index, summary_index=setup_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read articles from the web and add to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_news import get_stock_news\n",
    "symbol=\"INTC\"\n",
    "articles=get_stock_news(symbol)\n",
    "vector_index, summary_index = read_indexes()\n",
    "add_to_indexes(articles, vector_index, summary_index)\n",
    "save_indexes(vector_index, summary_index, dir_suffix=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_sample_node(VECTOR_INDEX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool, FunctionTool\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "from llama_index.core.vector_stores import FilterCondition, MetadataFilters\n",
    "\n",
    "def calculator(a:float, b:float, op:str):\n",
    "    \"\"\" performs operation op on a and b.  \n",
    "    Possible 'ops'are as follows: \n",
    "    '+':addition\n",
    "    '-': minus\n",
    "    '*': multiply\n",
    "    '/': divide\n",
    "    '%chg': percentage change from a to b\n",
    "    'chg':  absolute value of change\n",
    "    \"\"\"\n",
    "    if op == \"+\": return a+b\n",
    "    elif op == \"-\": return a-b\n",
    "    elif op == \"*\": return a*b\n",
    "    elif op == \"/\": return a/b\n",
    "    elif op == \"ch\": return abs(a-b)\n",
    "    elif op==\"%chg\": return round(100*(b/a-1))\n",
    "    else:\n",
    "         raise NotImplementedError\n",
    "\n",
    "vector_query_engine=vector_index.as_query_engine(filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
    "        ]))\n",
    "summary_query_engine=summary_index.as_query_engine()\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "        name=\"summary-tool\",\n",
    "        query_engine=summary_query_engine,\n",
    "        description=(\n",
    "            \"Useful for summarization questions related to stocks.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "        name=\"vector-tool\",\n",
    "        query_engine=vector_query_engine,\n",
    "        description=(\n",
    "            \"Useful for retrieving specific context from stock news.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "def vector_query(\n",
    "    query: str, \n",
    "    publication_date: str=None\n",
    ") -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "    \n",
    "    query (str): the string query to be embedded.\n",
    "    publication_date is the date on which the article was published.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    metadata_dicts = []\n",
    "    if publication_date is not None:\n",
    "        metadata_dicts.append({\"key\": \"published_at\", \"value\": publication_date})\n",
    "    \n",
    "    print(metadata_dicts)\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_query_tool\", \n",
    "    description=\"produces answers but limits to specified publication date\",\n",
    "    fn=vector_query\n",
    ")    \n",
    "\n",
    "\n",
    "def summary_query(\n",
    "    query: str, \n",
    "    publication_date: str=None\n",
    ") -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "    \n",
    "    query (str): the string query to be embedded.\n",
    "    publication_date is the date on which the article was published.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    metadata_dicts = []\n",
    "    if publication_date is not None:\n",
    "        metadata_dicts.append({\"key\": \"published_at\", \"value\": publication_date})\n",
    "    \n",
    "    query_engine = summary_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "summary_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"summary_query_tool\",\n",
    "    fn=vector_query,    \n",
    "    description=\"produces summary but limits to specified publication date\"\n",
    ")    \n",
    "\n",
    "math_tool = FunctionTool.from_defaults(\n",
    "    fn=calculator,\n",
    "    name=\"math_tool\",\n",
    "    description=\"\"\"Performs various math calculations: + - * / percent change & change\\n\n",
    "    \"performs operation op on a and b.  \n",
    "    Possible 'ops'are as follows: \n",
    "    '+':addition\n",
    "    '-': minus\n",
    "    '*': multiply\n",
    "    '/': divide\n",
    "    '%chg': percentage change from a to b\n",
    "    'chg':  absolute value of change\"\"\"\n",
    ")\n",
    "# router=RouterQueryEngine.from_defaults(\n",
    "#         selector=LLMSingleSelector.from_defaults(),\n",
    "#         query_engine_tools=[summary_tool, vector_tool],\n",
    "#         verbose=VERBOSE\n",
    "#         )\n",
    "\n",
    "# response=router.query(\" what was the percentage change in Apple's earnings this quarter compared with the same quarter in the prior year?\")\n",
    "# print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [summary_query_tool,math_tool, vector_query_tool], \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)\n",
    "response=agent.query(\"what was Intel's earnings this quarter  as reported on August 3 2024?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.query(\"what is the change (in %) from 105 to 119?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.query(\"Summarize Apple news in bullet form on Aug 3, 2024\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
