{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAzbOpr2Pucz"
      },
      "source": [
        "### Setting up langchain and chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbJP9wK8O_px"
      },
      "outputs": [],
      "source": [
        "!bash setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0La7IikQS3K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema.messages import HumanMessage, SystemMessage\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import (\n",
        "     PromptTemplate,\n",
        "     SystemMessagePromptTemplate,\n",
        "     HumanMessagePromptTemplate,\n",
        "     ChatPromptTemplate,\n",
        ")\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.docstore.document import Document\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from lib import id_maker, add_data_to_db\n",
        "dotenv.load_dotenv()\n",
        "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
        "CHROMA_PATH =  os.getenv(\"CHROMA_PATH\", \"./CHROMA_PATH\")\n",
        "COLLECTION_NAME= \"collection1\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZwQEPhfUJ_7"
      },
      "source": [
        "### Create Chroma database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drG8V6TSTm78"
      },
      "source": [
        "##### Clear the database -- note that you will have to restart the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Or8tvYTVMYD"
      },
      "outputs": [],
      "source": [
        "\n",
        "unique_id=id_maker(0).f\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    persist_directory=CHROMA_PATH,\n",
        "    embedding_function=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        ")\n",
        "urls=[\"https://en.wikipedia.org/wiki/Napoleon\"]\n",
        "add_data_to_db(urls, vector_store, unique_id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNrEDVsSTSbA"
      },
      "source": [
        "### Check if vector store insertions are working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfA0IuDLzVFO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# vector_store = Chroma(\n",
        "#     collection_name=COLLECTION_NAME,\n",
        "#     persist_directory=CHROMA_PATH,\n",
        "#     embedding_function=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY),\n",
        "#     )\n",
        "\n",
        "# retriever  = vector_store.as_retriever(k=10)\n",
        "# query=\"who was Napoleon?\"\n",
        "\n",
        "# results = retriever.invoke(query)\n",
        "\n",
        "# # Print the results\n",
        "# print(f\"Number of documents retrieved: {len(results)}\")\n",
        "# for doc in results:\n",
        "#     print(f\"Content: {doc.page_content}\")\n",
        "#     print(f\"Source: {doc.metadata['url']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM7H3esgUPsc"
      },
      "source": [
        "### Create retrieval chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN_Cm1A5yjvQ"
      },
      "outputs": [],
      "source": [
        "system_template_str = \"\"\"Your job is to to answer questions using\n",
        " context provided to answer questions.\n",
        " Be as detailed as possible, but don't make up any information\n",
        " that's not from the context. If the answer does not directly follow from context,\n",
        " say\n",
        " you don't know.  Please state the url from which this information was extracted.\n",
        " The url is in the metadata for each document in the context supplied for the prompt.\n",
        "\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "system_prompt = SystemMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"context\"], template=system_template_str\n",
        "     )\n",
        " )\n",
        "\n",
        "human_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"question\"], template=\"{question}\"\n",
        "    )\n",
        ")\n",
        "\n",
        "messages = [system_prompt, human_prompt]\n",
        "prompt_template = ChatPromptTemplate(\n",
        "     input_variables=[\"context\", \"question\"],\n",
        "    messages=messages,\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRRsVvtBOKLd"
      },
      "outputs": [],
      "source": [
        "def create_prompt(context, question):\n",
        "    return prompt_template.format(context=context, question=question)\n",
        "\n",
        "# Define the main chain\n",
        "def chain(question):\n",
        "    # Retrieve documents\n",
        "    docs = retriever.invoke(question)\n",
        "    #print(question, docs)\n",
        "    context = \" \".join([doc.page_content + \" url:\" + doc.metadata[\"url\"] +\"\\n\"\n",
        "                        for doc in docs])\n",
        "    # Create prompt\n",
        "    prompt = create_prompt(context, question)\n",
        "    print(prompt)\n",
        "    # Get response from the language model\n",
        "    chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0,\n",
        "                        openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "    response = chat_model.invoke(prompt)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAceCoZEUQFk"
      },
      "outputs": [],
      "source": [
        "result = chain(\"Who was Napoleon's daughter?\")\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
